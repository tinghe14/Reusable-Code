!pip install transformers

from google.colab import drive
drive.mount('/content/drive/')
import os

#copy the custom module from google drive to colab temporary drive
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/data_process.py /content/data_process.py
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/model.py /content/model.py
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/task.py /content/task.py
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/test.py /content/test.py
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/train.py /content/train.py
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/utils.py /content/utils.py
if not os.path.exists('/content/input'):
  os.makedirs('/content/input', exist_ok=True)
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/input/devel.tsv /content/input/devel.tsv
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/input/test.tsv /content/input/test.tsv
!cp /content/drive/MyDrive/Ting/ACL2023/input/Gene_NER_Clean_Script_wocluster/input/train.tsv /content/input/train.tsv

from data_process import *
from train import *
from utils import *
from test import *
import argparse

def get_args():
    '''
    Argument parser
    @Return: dict of arguments
    '''
    parser = argparse.ArgumentParser(description='Gene NER')

    parser.add_argument("-f", "--fff", help="a dummy argument to fool ipython", default="1")

    # input
    parser.add_argument('--input_dir', type=str, default='/content/input/', help='directory of original trian, test, dev and merge files')
    parser.add_argument('--split_random_state', type=int, default=1, help='random state to split train/test sets (default:1)')
    parser.add_argument('--split_test_fraction', type=float, default=0.2, help='fraction of test dataset among train dataset (default:0.2)')

    # clean
    parser.add_argument('--clean_dir', type=str, default='/content/input/clean/', help='directory of clean train, test, train_tag,  test_tag and tag_set files')

    # output
    parser.add_argument('--saved_dir', type=str, default='/content/output/', help='directory of saved models, plots and results')

    # train
    parser.add_argument('--epochs', type=int, default=3, help='number of epochs to train (default:3)')
    parser.add_argument('--lr', type=float, default=3e-5, help='learning rate (default:3e-5)')
    parser.add_argument('--train_batch_size', type=int, default=16, help='training batch size (default:16)')

    # environment
    parser.add_argument('--seed', type=int, default=1, help='random seed (default:1)')

    # embedding
    parser.add_argument('--pad_id', type=int, default=0, help='embedding word_pad_id (default:0)')
    parser.add_argument('--pad', type=str, default='<VOID>', help='embedding word_pad (default:<VOID>)')

    # training
    # parser.add_argument('--pretrained_model', type=str, default='dmis-lab/biobert-v1.1', help='pretrained model (default:biobert-v1.1)')
    # parser.add_argument('--max_seq_len', type=int, default=115, help='maximum sequence length (default: 115)')

    args = parser.parse_args()
    return args

def main():
    '''
    run the project
    '''
    # ---- main.py ---- #
    args = get_args()
    #device = torch.device("cuda:%d" % args.gpu_device)
    args.result = {}

    # ---- data_process.py ---- #
    # Merge File
    merge_files(args)

    # Generate Token per Row
    df = clean_token(args)

    # Describe the Data
    summary(df)

    # Vectorize Tag of Token and Split Data into Train and Test Set
    prepare_data(df, args)

    # ---- train.py ---- #
    train_sents = get_train_sent(args)
    test_sents = get_test_sent(args)
    train_tags = get_train_tag(args)
    test_tags = get_test_tag(args)
    tag_set = get_tag_set(args)

    #  return detailed error message when using GPU training
    os.environ['CUDA_LAUNCH_BLOCKING'] = "1"
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    train_bioberttagger(train_sents, train_tags, test_sents, test_tags, tag_set, args, DEVICE)

    # ---- test.py ---- #
    best_model_cp, last_model_cp = load_model(args, DEVICE)

    test_last_model(last_model_cp, train_sents, train_tags, test_sents, test_tags, args, DEVICE)
    test_best_model(best_model_cp, train_sents, train_tags, test_sents, test_tags, args, DEVICE)

# ---- main.py ---- #
main()
